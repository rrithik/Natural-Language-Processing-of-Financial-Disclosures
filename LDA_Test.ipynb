{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded 9 financial keywords.\n",
            "\n",
            "Topic 0:\n",
            "  0.003 * 'type'\n",
            "  0.003 * 'entityfilenumber'\n",
            "  0.003 * 'prefix'\n",
            "  0.003 * 'nke'\n",
            "  0.003 * 'dei'\n",
            "  0.003 * 'sec'\n",
            "  0.003 * 'sequence'\n",
            "  0.003 * 'conformed'\n",
            "  0.003 * 'pre'\n",
            "  0.003 * 'xbrl'\n",
            "\n",
            "Topic 1:\n",
            "  0.003 * 'type'\n",
            "  0.003 * 'balance'\n",
            "  0.003 * 'dei'\n",
            "  0.003 * 'securities'\n",
            "  0.003 * 'number'\n",
            "  0.003 * 'role'\n",
            "  0.003 * 'xbrli'\n",
            "  0.003 * 'film'\n",
            "  0.003 * 'data'\n",
            "  0.003 * 'htm'\n",
            "\n",
            "Topic 2:\n",
            "  0.003 * 'type'\n",
            "  0.003 * 'details'\n",
            "  0.003 * 'period'\n",
            "  0.003 * 'false'\n",
            "  0.003 * 'end'\n",
            "  0.003 * 'beaverton'\n",
            "  0.003 * 'report'\n",
            "  0.003 * 'dei'\n",
            "  0.003 * 'extension'\n",
            "  0.003 * 'officer'\n",
            "\n",
            "Topic 3:\n",
            "  0.003 * 'voluntarily'\n",
            "  0.003 * 'entityaddressstateorprovince'\n",
            "  0.003 * 'title'\n",
            "  0.003 * 'irs'\n",
            "  0.003 * 'footwear'\n",
            "  0.003 * 'assigned'\n",
            "  0.003 * 'tradingsymbolitemtype'\n",
            "  0.003 * 'limited'\n",
            "  0.003 * 'available'\n",
            "  0.003 * 'identification'\n",
            "\n",
            "Topic 4:\n",
            "  0.052 * 'type'\n",
            "  0.033 * 'dei'\n",
            "  0.027 * 'document'\n",
            "  0.021 * 'definition'\n",
            "  0.019 * 'entity'\n",
            "  0.017 * 'number'\n",
            "  0.017 * 'period'\n",
            "  0.016 * 'exchange'\n",
            "  0.015 * 'act'\n",
            "  0.014 * 'data'\n",
            "\n",
            "Topic 5:\n",
            "  0.005 * 'type'\n",
            "  0.004 * 'dei'\n",
            "  0.003 * 'document'\n",
            "  0.003 * 'exchange'\n",
            "  0.003 * 'address'\n",
            "  0.003 * 'details'\n",
            "  0.003 * 'entity'\n",
            "  0.003 * 'definition'\n",
            "  0.003 * 'act'\n",
            "  0.003 * 'sec'\n",
            "\n",
            "Topic 6:\n",
            "  0.004 * 'document'\n",
            "  0.004 * 'type'\n",
            "  0.003 * 'definition'\n",
            "  0.003 * 'period'\n",
            "  0.003 * 'data'\n",
            "  0.003 * 'xbrl'\n",
            "  0.003 * 'address'\n",
            "  0.003 * 'company'\n",
            "  0.003 * 'na'\n",
            "  0.003 * 'description'\n",
            "\n",
            "Topic 7:\n",
            "  0.006 * 'type'\n",
            "  0.004 * 'dei'\n",
            "  0.004 * 'document'\n",
            "  0.004 * 'definition'\n",
            "  0.004 * 'period'\n",
            "  0.004 * 'text'\n",
            "  0.004 * 'prefix'\n",
            "  0.004 * 'namespace'\n",
            "  0.004 * 'false'\n",
            "  0.003 * 'entity'\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from collections import Counter\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# 1. Load your financial text\n",
        "filename = \"0000320187-25-000053.txt\"\n",
        "with open(filename, \"r\", encoding=\"utf-8\") as f:\n",
        "    text_data = f.read()\n",
        "\n",
        "\n",
        "\n",
        "# 2. Basic text cleaning\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
        "    tokens = text.split()\n",
        "    return \" \".join(tokens)\n",
        "\n",
        "\n",
        "cleaned_text = clean_text(text_data)\n",
        "\n",
        "\n",
        "\n",
        "# 3. Load your financial keywords (from exmaples file: topics_v1, topics_v2)\n",
        "def load_topic_words(path):\n",
        "    words = []\n",
        "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
        "        for line in f:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                words.append(line.lower())\n",
        "    return words\n",
        "\n",
        "topic_v1 = load_topic_words(\"topics_v1.txt\")\n",
        "topic_v2 = load_topic_words(\"topics_v2.txt\")\n",
        "financial_seed_words = list(set(topic_v1 + topic_v2))\n",
        "\n",
        "print(f\"Loaded {len(financial_seed_words)} financial keywords.\")\n",
        "\n",
        "\n",
        "# =========================================\n",
        "# 4. Vectorize the document\n",
        "# =========================================\n",
        "vectorizer = CountVectorizer(\n",
        "    max_df=1.0,\n",
        "    min_df=1,\n",
        "    stop_words=\"english\",\n",
        ")\n",
        "\n",
        "doc_matrix = vectorizer.fit_transform([cleaned_text])\n",
        "\n",
        "\n",
        "\n",
        "# 5. Train small LDA model\n",
        "n_topics = 8  # change as needed\n",
        "\n",
        "lda_model = LatentDirichletAllocation(\n",
        "    n_components=n_topics,\n",
        "    max_iter=20,\n",
        "    learning_method=\"online\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lda_model.fit(doc_matrix)\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "\n",
        "# 6. Print topics (similar to gensim output)\n",
        "def print_topics(model, feature_names, n_top_words=10):\n",
        "    for idx, topic in enumerate(model.components_):\n",
        "        print(f\"\\nTopic {idx}:\")\n",
        "        top_indices = topic.argsort()[-n_top_words:][::-1]\n",
        "        for i in top_indices:\n",
        "            weight = topic[i] / topic.sum()\n",
        "            print(f\"  {weight:.3f} * '{feature_names[i]}'\")\n",
        "\n",
        "\n",
        "print_topics(lda_model, feature_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
