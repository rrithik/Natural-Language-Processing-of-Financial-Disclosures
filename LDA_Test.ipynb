{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loaded: wrds_text_data.txt\n",
            "Length: 35917232 characters\n",
            "Vocabulary size: 27176\n",
            "\n",
            "===== Topic 0 =====\n",
            "font, td, style, px, pt, nbsp, size, div, family, valign, align, padding, roman, margin, times, \n",
            "\n",
            "\n",
            "===== Topic 1 =====\n",
            "font, td, style, size, pt, nbsp, family, px, div, valign, padding, align, left, text, roman, \n",
            "\n",
            "\n",
            "===== Topic 2 =====\n",
            "enormous, distributions, affecting, convenience, workiva, style, lelewqzykmmeo, flj, lrpjq, oss, eiq, avoidability, fbr, usxl, family, \n",
            "\n",
            "\n",
            "===== Topic 3 =====\n",
            "font, td, style, pt, size, px, nbsp, valign, family, padding, align, div, times, margin, new, \n",
            "\n",
            "\n",
            "===== Topic 4 =====\n",
            "font, td, size, style, pt, nbsp, valign, px, div, family, padding, align, new, roman, tr, \n",
            "\n",
            "\n",
            "===== Topic 5 =====\n",
            "font, td, style, pt, px, size, family, valign, nbsp, div, padding, align, roman, new, text, \n",
            "\n",
            "\n",
            "===== Topic 6 =====\n",
            "td, font, size, style, px, nbsp, pt, align, valign, div, family, padding, times, left, text, \n",
            "\n",
            "\n",
            "===== Topic 7 =====\n",
            "font, td, pt, size, style, nbsp, px, family, valign, padding, align, div, roman, left, times, \n",
            "\n",
            "\n",
            "===== Topic 8 =====\n",
            "font, td, style, pt, px, nbsp, size, div, padding, family, align, valign, text, tr, left, \n",
            "\n",
            "\n",
            "===== Topic 9 =====\n",
            "font, td, style, size, nbsp, pt, div, px, family, valign, roman, left, times, padding, align, \n",
            "\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.decomposition import LatentDirichletAllocation\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 1. Load the WRDS combined text file\n",
        "# ============================================================\n",
        "\n",
        "FILENAME = \"wrds_text_data.txt\"   # <-- this is your file!\n",
        "\n",
        "with open(FILENAME, \"r\", errors=\"ignore\") as f:\n",
        "    text_data = f.read()\n",
        "\n",
        "print(\"Loaded:\", FILENAME)\n",
        "print(\"Length:\", len(text_data), \"characters\")\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 2. Clean the full text\n",
        "# ============================================================\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()\n",
        "    text = re.sub(r\"[^a-z\\s]\", \" \", text)\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "    return text.strip()\n",
        "\n",
        "cleaned_text = clean_text(text_data)\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 3. Vectorize ONE giant document\n",
        "# ============================================================\n",
        "\n",
        "vectorizer = CountVectorizer(\n",
        "    max_df=1.0,\n",
        "    min_df=1,               # important for 1-document LDA\n",
        "    stop_words=\"english\",\n",
        ")\n",
        "\n",
        "doc_matrix = vectorizer.fit_transform([cleaned_text])\n",
        "\n",
        "print(\"Vocabulary size:\", len(vectorizer.get_feature_names_out()))\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 4. Fit LDA model\n",
        "# ============================================================\n",
        "\n",
        "N_TOPICS = 10\n",
        "\n",
        "lda_model = LatentDirichletAllocation(\n",
        "    n_components=N_TOPICS,\n",
        "    max_iter=20,\n",
        "    learning_method=\"online\",\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "lda_model.fit(doc_matrix)\n",
        "\n",
        "feature_names = vectorizer.get_feature_names_out()\n",
        "\n",
        "\n",
        "# ============================================================\n",
        "# 5. Print topics\n",
        "# ============================================================\n",
        "\n",
        "def print_topics(model, feature_names, n_top_words=15):\n",
        "    for idx, topic in enumerate(model.components_):\n",
        "        print(f\"\\n===== Topic {idx} =====\")\n",
        "        top_indices = topic.argsort()[-n_top_words:][::-1]\n",
        "        for i in top_indices:\n",
        "            print(feature_names[i], end=\", \")\n",
        "        print(\"\\n\")\n",
        "\n",
        "print_topics(lda_model, feature_names)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.14.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
